C:\Users\naked\AppData\Local\conda\conda\envs\7030\python.exe C:/dev/cnnpruner/POC.py
Files already downloaded and verified
Files already downloaded and verified
***  vgg16 0
number of flops: 17315688448.0 	number of params: 138357536.0
C:\dev\cnnpruner\deeplib_ext\CustomDeepLib.py:129: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.
  inputs = Variable(inputs, volatile=True)
C:\dev\cnnpruner\deeplib_ext\CustomDeepLib.py:130: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.
  targets = Variable(targets, volatile=True)
Test:
	Score: 0.0
Epoch 0 - Train acc: 87.80 - Val acc: 85.36 - Train loss: 0.3450 - Val loss: 0.4244 - Training time: 322.47s
Epoch 1 - Train acc: 93.03 - Val acc: 88.51 - Train loss: 0.2028 - Val loss: 0.3261 - Training time: 324.58s
Epoch 2 - Train acc: 96.64 - Val acc: 91.28 - Train loss: 0.1100 - Val loss: 0.2547 - Training time: 327.82s
Epoch 3 - Train acc: 97.09 - Val acc: 90.93 - Train loss: 0.0872 - Val loss: 0.2910 - Training time: 326.85s
Epoch 4 - Train acc: 98.36 - Val acc: 91.64 - Train loss: 0.0491 - Val loss: 0.2738 - Training time: 322.00s
Epoch 5 - Train acc: 99.06 - Val acc: 92.30 - Train loss: 0.0294 - Val loss: 0.2792 - Training time: 322.06s
Epoch 6 - Train acc: 99.52 - Val acc: 92.36 - Train loss: 0.0167 - Val loss: 0.2796 - Training time: 320.99s
Epoch 7 - Train acc: 99.83 - Val acc: 92.95 - Train loss: 0.0078 - Val loss: 0.2771 - Training time: 321.00s
Epoch 8 - Train acc: 99.54 - Val acc: 91.92 - Train loss: 0.0146 - Val loss: 0.3380 - Training time: 321.03s
Epoch 9 - Train acc: 99.74 - Val acc: 92.57 - Train loss: 0.0087 - Val loss: 0.3119 - Training time: 320.94s
Epoch 10 - Train acc: 99.86 - Val acc: 93.04 - Train loss: 0.0050 - Val loss: 0.3269 - Training time: 320.90s
Epoch 11 - Train acc: 99.71 - Val acc: 92.43 - Train loss: 0.0092 - Val loss: 0.3659 - Training time: 320.99s
Epoch 12 - Train acc: 99.98 - Val acc: 93.55 - Train loss: 0.0008 - Val loss: 0.3180 - Training time: 321.00s
Epoch 13 - Train acc: 99.94 - Val acc: 93.32 - Train loss: 0.0024 - Val loss: 0.3094 - Training time: 320.93s
Epoch 14 - Train acc: 99.74 - Val acc: 92.49 - Train loss: 0.0076 - Val loss: 0.3808 - Training time: 320.96s
end number of flops: 17315688448.0 	number of params: 138357536.0
Final Test:
	Score: 91.92
***  vgg16 30
number of flops: 17315688448.0 	number of params: 138357536.0
Epoch 0 - Train acc: 91.40 - Val acc: 88.85 - Train loss: 0.2612 - Val loss: 0.3281 - Training time: 320.67s
Epoch 1 - Train acc: 95.34 - Val acc: 91.14 - Train loss: 0.1419 - Val loss: 0.2545 - Training time: 320.70s
Epoch 2 - Train acc: 97.12 - Val acc: 92.04 - Train loss: 0.0921 - Val loss: 0.2418 - Training time: 320.64s
Epoch 3 - Train acc: 98.54 - Val acc: 92.87 - Train loss: 0.0469 - Val loss: 0.2165 - Training time: 320.71s
Epoch 4 - Train acc: 99.04 - Val acc: 92.49 - Train loss: 0.0315 - Val loss: 0.2511 - Training time: 320.75s
Test:
	Score: 92.01
6 iterations to reduce 30.00% filters
Perform pruning iteration: 0
Layers that will be pruned {'features.24': 20, 'features.10': 9, 'features.28': 68, 'features.7': 2, 'features.21': 26, 'features.17': 21, 'features.2': 2, 'features.12': 7, 'features.26': 30, 'features.19': 16, 'features.14': 8, 'features.5': 1, 'features.0': 1}
convolution remaining after pruning {'features.24': 492, 'features.10': 247, 'features.28': 444, 'features.7': 126, 'features.21': 486, 'features.17': 491, 'features.2': 62, 'features.12': 249, 'features.26': 482, 'features.19': 496, 'features.14': 248, 'features.5': 127, 'features.0': 63}
Pruning filters.. 
Filters pruned 4.995265151515151%
Test:
	post prune Score: 90.34
Fine tuning to recover from prunning iteration.
Epoch 0 - Train acc: 96.52 - Val acc: 94.77 - Train loss: 0.0985 - Val loss: 0.1468 - Training time: 315.23s
Test pruning iteration :0
	Score: 89.83
Perform pruning iteration: 1
Layers that will be pruned {'features.19': 22, 'features.21': 34, 'features.28': 35, 'features.17': 31, 'features.26': 30, 'features.24': 27, 'features.5': 3, 'features.7': 9, 'features.12': 7, 'features.14': 5, 'features.10': 4, 'features.0': 2, 'features.2': 1}
convolution remaining after pruning {'features.19': 474, 'features.21': 452, 'features.28': 409, 'features.17': 460, 'features.26': 452, 'features.24': 465, 'features.5': 124, 'features.7': 117, 'features.12': 242, 'features.14': 243, 'features.10': 243, 'features.0': 61, 'features.2': 61}
Pruning filters.. 
Filters pruned 4.995265151515151%
Test:
	post prune Score: 84.91
Fine tuning to recover from prunning iteration.
Epoch 0 - Train acc: 98.06 - Val acc: 96.30 - Train loss: 0.0571 - Val loss: 0.1033 - Training time: 301.17s
Test pruning iteration :1
	Score: 91.47
Perform pruning iteration: 2
Layers that will be pruned {'features.21': 20, 'features.28': 61, 'features.24': 29, 'features.26': 38, 'features.19': 15, 'features.17': 29, 'features.5': 1, 'features.14': 3, 'features.10': 6, 'features.2': 2, 'features.12': 7}
convolution remaining after pruning {'features.21': 432, 'features.28': 348, 'features.24': 436, 'features.26': 414, 'features.19': 459, 'features.17': 431, 'features.5': 123, 'features.14': 240, 'features.10': 237, 'features.2': 59, 'features.12': 235}
Pruning filters.. 
Filters pruned 4.995265151515151%
Test:
	post prune Score: 89.46
Fine tuning to recover from prunning iteration.
Epoch 0 - Train acc: 98.20 - Val acc: 96.86 - Train loss: 0.0555 - Val loss: 0.0924 - Training time: 293.32s
Test pruning iteration :2
	Score: 91.5
Perform pruning iteration: 3
Layers that will be pruned {'features.14': 9, 'features.17': 21, 'features.19': 31, 'features.24': 35, 'features.2': 1, 'features.26': 35, 'features.10': 9, 'features.0': 2, 'features.28': 33, 'features.12': 9, 'features.7': 5, 'features.5': 3, 'features.21': 18}
convolution remaining after pruning {'features.14': 231, 'features.17': 410, 'features.19': 428, 'features.24': 401, 'features.2': 58, 'features.26': 379, 'features.10': 228, 'features.0': 59, 'features.28': 315, 'features.12': 226, 'features.7': 112, 'features.5': 120, 'features.21': 414}
Pruning filters.. 
Filters pruned 4.995265151515151%
Test:
	post prune Score: 90.02
Fine tuning to recover from prunning iteration.
Epoch 0 - Train acc: 98.91 - Val acc: 97.76 - Train loss: 0.0360 - Val loss: 0.0635 - Training time: 281.94s
Test pruning iteration :3
	Score: 92.15
Perform pruning iteration: 4
Layers that will be pruned {'features.21': 27, 'features.19': 34, 'features.24': 25, 'features.26': 27, 'features.7': 5, 'features.12': 17, 'features.17': 20, 'features.14': 12, 'features.5': 5, 'features.28': 28, 'features.0': 1, 'features.2': 1, 'features.10': 9}
convolution remaining after pruning {'features.21': 387, 'features.19': 394, 'features.24': 376, 'features.26': 352, 'features.7': 107, 'features.12': 209, 'features.17': 390, 'features.14': 219, 'features.5': 115, 'features.28': 287, 'features.0': 58, 'features.2': 57, 'features.10': 219}
Pruning filters.. 
Filters pruned 4.995265151515151%
Test:
	post prune Score: 87.74
Fine tuning to recover from prunning iteration.
Epoch 0 - Train acc: 98.92 - Val acc: 97.54 - Train loss: 0.0385 - Val loss: 0.0737 - Training time: 269.59s
Test pruning iteration :4
	Score: 92.16
Perform pruning iteration: 5
Layers that will be pruned {'features.21': 32, 'features.12': 11, 'features.19': 25, 'features.5': 7, 'features.24': 36, 'features.26': 23, 'features.10': 8, 'features.14': 8, 'features.17': 28, 'features.28': 25, 'features.7': 5, 'features.0': 2, 'features.2': 1}
convolution remaining after pruning {'features.21': 355, 'features.12': 198, 'features.19': 369, 'features.5': 108, 'features.24': 340, 'features.26': 329, 'features.10': 211, 'features.14': 211, 'features.17': 362, 'features.28': 262, 'features.7': 102, 'features.0': 56, 'features.2': 56}
Pruning filters.. 
Filters pruned 4.995265151515151%
Test:
	post prune Score: 85.77
Fine tuning to recover from prunning iteration.
Epoch 0 - Train acc: 98.03 - Val acc: 96.40 - Train loss: 0.0613 - Val loss: 0.1046 - Training time: 243.48s
Test pruning iteration :5
	Score: 91.24
Epoch 0 - Train acc: 99.04 - Val acc: 98.08 - Train loss: 0.0324 - Val loss: 0.0557 - Training time: 243.50s
Epoch 1 - Train acc: 99.48 - Val acc: 98.06 - Train loss: 0.0184 - Val loss: 0.0577 - Training time: 243.58s
Epoch 2 - Train acc: 99.81 - Val acc: 98.37 - Train loss: 0.0084 - Val loss: 0.0481 - Training time: 243.55s
Epoch 3 - Train acc: 99.53 - Val acc: 97.93 - Train loss: 0.0132 - Val loss: 0.0634 - Training time: 243.55s
end number of flops: 10552109056.0 	number of params: 80536248.0
Final Test:
	Score: 92.03
***  Resnet 18-0
number of flops: 1825668096.0 	number of params: 11181642.0
Test:
	Score: 13.309999999999999
Epoch 0 - Train acc: 93.91 - Val acc: 92.00 - Train loss: 0.2022 - Val loss: 0.2522 - Training time: 100.33s
Epoch 1 - Train acc: 97.35 - Val acc: 93.75 - Train loss: 0.0976 - Val loss: 0.1856 - Training time: 100.02s
Epoch 2 - Train acc: 98.82 - Val acc: 94.25 - Train loss: 0.0542 - Val loss: 0.1711 - Training time: 100.08s
Epoch 3 - Train acc: 99.58 - Val acc: 94.32 - Train loss: 0.0291 - Val loss: 0.1684 - Training time: 100.11s
Epoch 4 - Train acc: 99.89 - Val acc: 94.54 - Train loss: 0.0157 - Val loss: 0.1648 - Training time: 100.27s
Epoch 5 - Train acc: 99.97 - Val acc: 94.60 - Train loss: 0.0084 - Val loss: 0.1687 - Training time: 100.05s
Epoch 6 - Train acc: 99.99 - Val acc: 94.45 - Train loss: 0.0053 - Val loss: 0.1714 - Training time: 100.06s
Epoch 7 - Train acc: 100.00 - Val acc: 94.45 - Train loss: 0.0038 - Val loss: 0.1727 - Training time: 99.81s
Epoch 8 - Train acc: 100.00 - Val acc: 94.86 - Train loss: 0.0025 - Val loss: 0.1728 - Training time: 99.95s
Epoch 9 - Train acc: 100.00 - Val acc: 94.68 - Train loss: 0.0018 - Val loss: 0.1743 - Training time: 100.10s
Epoch 10 - Train acc: 100.00 - Val acc: 94.64 - Train loss: 0.0017 - Val loss: 0.1802 - Training time: 100.05s
Epoch 11 - Train acc: 100.00 - Val acc: 94.68 - Train loss: 0.0011 - Val loss: 0.1757 - Training time: 100.20s
Epoch 12 - Train acc: 100.00 - Val acc: 94.70 - Train loss: 0.0010 - Val loss: 0.1812 - Training time: 100.13s
Epoch 13 - Train acc: 100.00 - Val acc: 94.66 - Train loss: 0.0009 - Val loss: 0.1828 - Training time: 100.44s
Epoch 14 - Train acc: 100.00 - Val acc: 94.79 - Train loss: 0.0007 - Val loss: 0.1840 - Training time: 99.91s
end number of flops: 1825668096.0 	number of params: 11181642.0
Final Test:
	Score: 94.61
***  Resnet 18-30
number of flops: 1825668096.0 	number of params: 11181642.0
Epoch 0 - Train acc: 94.01 - Val acc: 92.25 - Train loss: 0.1953 - Val loss: 0.2372 - Training time: 99.89s
Epoch 1 - Train acc: 95.21 - Val acc: 92.18 - Train loss: 0.1469 - Val loss: 0.2326 - Training time: 100.18s
Epoch 2 - Train acc: 98.11 - Val acc: 93.70 - Train loss: 0.0740 - Val loss: 0.1860 - Training time: 100.09s
Epoch 3 - Train acc: 99.51 - Val acc: 94.50 - Train loss: 0.0307 - Val loss: 0.1705 - Training time: 99.99s
Epoch 4 - Train acc: 99.91 - Val acc: 94.58 - Train loss: 0.0148 - Val loss: 0.1679 - Training time: 99.97s
Test:
	Score: 94.21000000000001
6 iterations to reduce 30.00% filters
Perform pruning iteration: 0
Layers that will be pruned {'layer4.0.conv1': 25, 'layer4.1.conv1': 36, 'layer2.1.conv1': 4, 'layer3.1.conv1': 14, 'layer3.0.conv1': 11, 'layer2.0.conv1': 5, 'layer1.1.conv1': 1}
convolution remaining after pruning {'layer4.0.conv1': 487, 'layer4.1.conv1': 476, 'layer2.1.conv1': 124, 'layer3.1.conv1': 242, 'layer3.0.conv1': 245, 'layer2.0.conv1': 123, 'layer1.1.conv1': 63}
Pruning filters.. 
Filters pruned 5.0%
Test:
	post prune Score: 10.45
Fine tuning to recover from prunning iteration.
Epoch 0 - Train acc: 96.12 - Val acc: 92.31 - Train loss: 0.1327 - Val loss: 0.2158 - Training time: 100.09s
Test pruning iteration :0
	Score: 90.92
Perform pruning iteration: 1
Layers that will be pruned {'layer2.0.conv1': 5, 'layer4.1.conv1': 41, 'layer4.0.conv1': 33, 'layer3.0.conv1': 5, 'layer3.1.conv1': 8, 'layer2.1.conv1': 2, 'layer1.1.conv1': 1, 'layer1.0.conv1': 1}
convolution remaining after pruning {'layer2.0.conv1': 118, 'layer4.1.conv1': 435, 'layer4.0.conv1': 454, 'layer3.0.conv1': 240, 'layer3.1.conv1': 234, 'layer2.1.conv1': 122, 'layer1.1.conv1': 62, 'layer1.0.conv1': 63}
Pruning filters.. 
Filters pruned 5.0%
Test:
	post prune Score: 10.0
Fine tuning to recover from prunning iteration.
Epoch 0 - Train acc: 95.66 - Val acc: 92.82 - Train loss: 0.1415 - Val loss: 0.2068 - Training time: 99.93s
Test pruning iteration :1
	Score: 91.11
Perform pruning iteration: 2
Layers that will be pruned {'layer1.0.conv1': 6, 'layer4.0.conv1': 31, 'layer3.0.conv1': 5, 'layer4.1.conv1': 31, 'layer1.1.conv1': 3, 'layer2.0.conv1': 5, 'layer3.1.conv1': 9, 'layer2.1.conv1': 6}
convolution remaining after pruning {'layer1.0.conv1': 57, 'layer4.0.conv1': 423, 'layer3.0.conv1': 235, 'layer4.1.conv1': 404, 'layer1.1.conv1': 59, 'layer2.0.conv1': 113, 'layer3.1.conv1': 225, 'layer2.1.conv1': 116}
Pruning filters.. 
Filters pruned 5.0%
Test:
	post prune Score: 10.0
Fine tuning to recover from prunning iteration.
Epoch 0 - Train acc: 96.47 - Val acc: 93.60 - Train loss: 0.1187 - Val loss: 0.1859 - Training time: 100.08s
Test pruning iteration :2
	Score: 91.51
Perform pruning iteration: 3
Layers that will be pruned {'layer2.0.conv1': 5, 'layer4.0.conv1': 37, 'layer2.1.conv1': 2, 'layer4.1.conv1': 28, 'layer3.1.conv1': 8, 'layer1.1.conv1': 4, 'layer3.0.conv1': 9, 'layer1.0.conv1': 3}
convolution remaining after pruning {'layer2.0.conv1': 108, 'layer4.0.conv1': 386, 'layer2.1.conv1': 114, 'layer4.1.conv1': 376, 'layer3.1.conv1': 217, 'layer1.1.conv1': 55, 'layer3.0.conv1': 226, 'layer1.0.conv1': 54}
Pruning filters.. 
Filters pruned 5.0%
Test:
	post prune Score: 10.0
Fine tuning to recover from prunning iteration.
Epoch 0 - Train acc: 96.38 - Val acc: 92.96 - Train loss: 0.1202 - Val loss: 0.1959 - Training time: 99.75s
Test pruning iteration :3
	Score: 91.47999999999999
Perform pruning iteration: 4
Layers that will be pruned {'layer4.1.conv1': 38, 'layer4.0.conv1': 36, 'layer3.0.conv1': 9, 'layer2.0.conv1': 4, 'layer3.1.conv1': 7, 'layer2.1.conv1': 2}
convolution remaining after pruning {'layer4.1.conv1': 338, 'layer4.0.conv1': 350, 'layer3.0.conv1': 217, 'layer2.0.conv1': 104, 'layer3.1.conv1': 210, 'layer2.1.conv1': 112}
Pruning filters.. 
Filters pruned 5.0%
Test:
	post prune Score: 10.0
Fine tuning to recover from prunning iteration.
Epoch 0 - Train acc: 97.23 - Val acc: 94.53 - Train loss: 0.0924 - Val loss: 0.1626 - Training time: 99.77s
Test pruning iteration :4
	Score: 92.13
Perform pruning iteration: 5
Layers that will be pruned {'layer4.1.conv1': 33, 'layer2.0.conv1': 6, 'layer4.0.conv1': 29, 'layer3.1.conv1': 10, 'layer3.0.conv1': 10, 'layer1.0.conv1': 2, 'layer2.1.conv1': 3, 'layer1.1.conv1': 3}
convolution remaining after pruning {'layer4.1.conv1': 305, 'layer2.0.conv1': 98, 'layer4.0.conv1': 321, 'layer3.1.conv1': 200, 'layer3.0.conv1': 207, 'layer1.0.conv1': 52, 'layer2.1.conv1': 109, 'layer1.1.conv1': 52}
Pruning filters.. 
Filters pruned 5.0%
Test:
	post prune Score: 10.0
Fine tuning to recover from prunning iteration.
Epoch 0 - Train acc: 97.17 - Val acc: 95.03 - Train loss: 0.0954 - Val loss: 0.1536 - Training time: 99.79s
Test pruning iteration :5
	Score: 92.07
Epoch 0 - Train acc: 98.54 - Val acc: 96.76 - Train loss: 0.0580 - Val loss: 0.0994 - Training time: 99.87s
Epoch 1 - Train acc: 99.53 - Val acc: 96.89 - Train loss: 0.0279 - Val loss: 0.0892 - Training time: 99.86s
Epoch 2 - Train acc: 99.86 - Val acc: 97.11 - Train loss: 0.0155 - Val loss: 0.0848 - Training time: 99.93s
Epoch 3 - Train acc: 99.97 - Val acc: 97.27 - Train loss: 0.0084 - Val loss: 0.0818 - Training time: 99.45s
end number of flops: 1421449984.0 	number of params: 7401930.0
Final Test:
	Score: 93.11
***  Alexnet 0
number of flops: 823247104.0 	number of params: 61100840.0
Test:
	Score: 0.01
Epoch 0 - Train acc: 82.38 - Val acc: 80.57 - Train loss: 0.5030 - Val loss: 0.5545 - Training time: 88.39s
Epoch 1 - Train acc: 85.94 - Val acc: 82.96 - Train loss: 0.4098 - Val loss: 0.4887 - Training time: 87.71s
Epoch 2 - Train acc: 91.15 - Val acc: 86.89 - Train loss: 0.2616 - Val loss: 0.3800 - Training time: 87.24s
Epoch 3 - Train acc: 91.79 - Val acc: 87.07 - Train loss: 0.2329 - Val loss: 0.3714 - Training time: 87.71s
Epoch 4 - Train acc: 94.54 - Val acc: 88.73 - Train loss: 0.1670 - Val loss: 0.3276 - Training time: 87.40s
Epoch 5 - Train acc: 95.34 - Val acc: 89.11 - Train loss: 0.1412 - Val loss: 0.3247 - Training time: 88.50s
Epoch 6 - Train acc: 95.27 - Val acc: 88.38 - Train loss: 0.1388 - Val loss: 0.3505 - Training time: 87.77s
Epoch 7 - Train acc: 97.20 - Val acc: 89.74 - Train loss: 0.0905 - Val loss: 0.3066 - Training time: 87.59s
Epoch 8 - Train acc: 97.99 - Val acc: 90.33 - Train loss: 0.0649 - Val loss: 0.2997 - Training time: 87.55s
Epoch 9 - Train acc: 98.10 - Val acc: 89.52 - Train loss: 0.0641 - Val loss: 0.3125 - Training time: 87.64s
Epoch 10 - Train acc: 98.90 - Val acc: 90.29 - Train loss: 0.0389 - Val loss: 0.3154 - Training time: 88.54s
Epoch 11 - Train acc: 99.21 - Val acc: 90.25 - Train loss: 0.0335 - Val loss: 0.3133 - Training time: 88.58s
Epoch 12 - Train acc: 99.36 - Val acc: 90.41 - Train loss: 0.0267 - Val loss: 0.3256 - Training time: 88.24s
Epoch 13 - Train acc: 99.13 - Val acc: 90.06 - Train loss: 0.0323 - Val loss: 0.3432 - Training time: 87.29s
Epoch 14 - Train acc: 99.42 - Val acc: 90.29 - Train loss: 0.0226 - Val loss: 0.3531 - Training time: 88.55s
end number of flops: 823247104.0 	number of params: 61100840.0
Final Test:
	Score: 90.59
***  Alexnet 30
number of flops: 823247104.0 	number of params: 61100840.0
Epoch 0 - Train acc: 81.41 - Val acc: 79.88 - Train loss: 0.5421 - Val loss: 0.5669 - Training time: 88.43s
Epoch 1 - Train acc: 86.75 - Val acc: 83.85 - Train loss: 0.3875 - Val loss: 0.4585 - Training time: 88.34s
Epoch 2 - Train acc: 91.20 - Val acc: 87.69 - Train loss: 0.2600 - Val loss: 0.3488 - Training time: 88.55s
Epoch 3 - Train acc: 90.93 - Val acc: 86.41 - Train loss: 0.2628 - Val loss: 0.4028 - Training time: 88.49s
Epoch 4 - Train acc: 94.15 - Val acc: 88.91 - Train loss: 0.1737 - Val loss: 0.3184 - Training time: 88.79s
Test:
	Score: 88.7
6 iterations to reduce 30.00% filters
Perform pruning iteration: 0
Layers that will be pruned {'features.6': 25, 'features.10': 13, 'features.3': 4, 'features.8': 11, 'features.0': 4}
convolution remaining after pruning {'features.6': 359, 'features.10': 243, 'features.3': 188, 'features.8': 245, 'features.0': 60}
Pruning filters.. 
Filters pruned 4.947916666666667%
Test:
	post prune Score: 10.13
Fine tuning to recover from prunning iteration.
Epoch 0 - Train acc: 92.74 - Val acc: 91.34 - Train loss: 0.2131 - Val loss: 0.2520 - Training time: 88.70s
Test pruning iteration :0
	Score: 88.64999999999999
Perform pruning iteration: 1
Layers that will be pruned {'features.10': 8, 'features.6': 28, 'features.0': 5, 'features.8': 12, 'features.3': 4}
convolution remaining after pruning {'features.10': 235, 'features.6': 331, 'features.0': 55, 'features.8': 233, 'features.3': 184}
Pruning filters.. 
Filters pruned 4.947916666666667%
Test:
	post prune Score: 30.64
Fine tuning to recover from prunning iteration.
Epoch 0 - Train acc: 94.54 - Val acc: 93.12 - Train loss: 0.1660 - Val loss: 0.2017 - Training time: 87.44s
Test pruning iteration :1
	Score: 89.53
Perform pruning iteration: 2
Layers that will be pruned {'features.8': 17, 'features.6': 21, 'features.10': 9, 'features.3': 8, 'features.0': 2}
convolution remaining after pruning {'features.8': 216, 'features.6': 310, 'features.10': 226, 'features.3': 176, 'features.0': 53}
Pruning filters.. 
Filters pruned 4.947916666666667%
Test:
	post prune Score: 44.57
Fine tuning to recover from prunning iteration.
Epoch 0 - Train acc: 94.55 - Val acc: 92.67 - Train loss: 0.1645 - Val loss: 0.2148 - Training time: 87.55s
Test pruning iteration :2
	Score: 89.25
Perform pruning iteration: 3
Layers that will be pruned {'features.6': 20, 'features.10': 16, 'features.8': 14, 'features.3': 2, 'features.0': 5}
convolution remaining after pruning {'features.6': 290, 'features.10': 210, 'features.8': 202, 'features.3': 174, 'features.0': 48}
Pruning filters.. 
Filters pruned 4.947916666666667%
Test:
	post prune Score: 42.449999999999996
Fine tuning to recover from prunning iteration.
Epoch 0 - Train acc: 93.24 - Val acc: 91.92 - Train loss: 0.1970 - Val loss: 0.2303 - Training time: 88.55s
Test pruning iteration :3
	Score: 87.99
Perform pruning iteration: 4
Layers that will be pruned {'features.8': 9, 'features.3': 14, 'features.6': 19, 'features.10': 12, 'features.0': 2}
convolution remaining after pruning {'features.8': 193, 'features.3': 160, 'features.6': 271, 'features.10': 198, 'features.0': 46}
Pruning filters.. 
Filters pruned 4.947916666666667%
Test:
	post prune Score: 71.53
Fine tuning to recover from prunning iteration.
Epoch 0 - Train acc: 92.07 - Val acc: 90.58 - Train loss: 0.2222 - Val loss: 0.2712 - Training time: 87.67s
Test pruning iteration :4
	Score: 86.55000000000001
Perform pruning iteration: 5
Layers that will be pruned {'features.8': 18, 'features.6': 24, 'features.10': 4, 'features.3': 9, 'features.0': 2}
convolution remaining after pruning {'features.8': 175, 'features.6': 247, 'features.10': 194, 'features.3': 151, 'features.0': 44}
Pruning filters.. 
Filters pruned 4.947916666666667%
Test:
	post prune Score: 75.13
Fine tuning to recover from prunning iteration.
Epoch 0 - Train acc: 93.74 - Val acc: 92.74 - Train loss: 0.1859 - Val loss: 0.2200 - Training time: 88.58s
Test pruning iteration :5
	Score: 88.12
end number of flops: 467602048.0 	number of params: 50702004.0
Final Test:
	Score: 88.12
***  Alexnet 0%
number of flops: 823247104.0 	number of params: 61100840.0
Epoch 0 - Train acc: 82.28 - Val acc: 80.28 - Train loss: 0.5145 - Val loss: 0.5704 - Training time: 88.81s
Epoch 1 - Train acc: 87.94 - Val acc: 84.79 - Train loss: 0.3536 - Val loss: 0.4357 - Training time: 88.25s
Epoch 2 - Train acc: 91.57 - Val acc: 88.22 - Train loss: 0.2517 - Val loss: 0.3483 - Training time: 87.42s
Test:
	Score: 87.7
Epoch 0 - Train acc: 91.85 - Val acc: 90.17 - Train loss: 0.2429 - Val loss: 0.2861 - Training time: 87.58s
Epoch 1 - Train acc: 93.08 - Val acc: 90.25 - Train loss: 0.2026 - Val loss: 0.2778 - Training time: 88.18s
Epoch 2 - Train acc: 95.32 - Val acc: 91.47 - Train loss: 0.1419 - Val loss: 0.2462 - Training time: 88.68s
Epoch 3 - Train acc: 96.05 - Val acc: 91.12 - Train loss: 0.1230 - Val loss: 0.2577 - Training time: 89.14s
Epoch 4 - Train acc: 96.00 - Val acc: 90.56 - Train loss: 0.1178 - Val loss: 0.2826 - Training time: 88.49s
Epoch 5 - Train acc: 97.82 - Val acc: 92.11 - Train loss: 0.0718 - Val loss: 0.2362 - Training time: 87.89s
Epoch 6 - Train acc: 98.47 - Val acc: 92.36 - Train loss: 0.0537 - Val loss: 0.2369 - Training time: 88.89s
Epoch 7 - Train acc: 98.80 - Val acc: 92.18 - Train loss: 0.0441 - Val loss: 0.2422 - Training time: 88.74s
Epoch 8 - Train acc: 98.79 - Val acc: 92.07 - Train loss: 0.0430 - Val loss: 0.2627 - Training time: 88.95s
Epoch 9 - Train acc: 99.23 - Val acc: 92.42 - Train loss: 0.0321 - Val loss: 0.2453 - Training time: 88.92s
Epoch 10 - Train acc: 98.98 - Val acc: 91.56 - Train loss: 0.0366 - Val loss: 0.2917 - Training time: 89.05s
Epoch 11 - Train acc: 99.69 - Val acc: 92.49 - Train loss: 0.0169 - Val loss: 0.2593 - Training time: 88.31s
end number of flops: 823247104.0 	number of params: 61100840.0
Final Test:
	Score: 91.23
***  Alexnet 10%
number of flops: 823247104.0 	number of params: 61100840.0
Epoch 0 - Train acc: 83.44 - Val acc: 82.62 - Train loss: 0.4795 - Val loss: 0.5056 - Training time: 87.86s
Epoch 1 - Train acc: 88.06 - Val acc: 86.09 - Train loss: 0.3474 - Val loss: 0.4057 - Training time: 88.80s
Epoch 2 - Train acc: 91.81 - Val acc: 88.57 - Train loss: 0.2459 - Val loss: 0.3285 - Training time: 88.63s
Test:
	Score: 88.13
2 iterations to reduce 10.00% filters
Perform pruning iteration: 0
Layers that will be pruned {'features.6': 28, 'features.10': 4, 'features.8': 13, 'features.3': 7, 'features.0': 5}
convolution remaining after pruning {'features.6': 356, 'features.10': 252, 'features.8': 243, 'features.3': 185, 'features.0': 59}
Pruning filters.. 
Filters pruned 4.947916666666667%
Test:
	post prune Score: 20.34
Fine tuning to recover from prunning iteration.
Epoch 0 - Train acc: 91.94 - Val acc: 90.58 - Train loss: 0.2396 - Val loss: 0.2755 - Training time: 88.83s
Epoch 1 - Train acc: 93.42 - Val acc: 91.25 - Train loss: 0.1980 - Val loss: 0.2520 - Training time: 88.55s
Epoch 2 - Train acc: 94.67 - Val acc: 90.99 - Train loss: 0.1629 - Val loss: 0.2530 - Training time: 88.26s
Test pruning iteration :0
	Score: 89.03999999999999
Perform pruning iteration: 1
Layers that will be pruned {'features.3': 6, 'features.8': 16, 'features.10': 14, 'features.6': 21}
convolution remaining after pruning {'features.3': 179, 'features.8': 227, 'features.10': 238, 'features.6': 335}
Pruning filters.. 
Filters pruned 4.947916666666667%
Test:
	post prune Score: 30.320000000000004
Fine tuning to recover from prunning iteration.
Epoch 0 - Train acc: 94.03 - Val acc: 92.32 - Train loss: 0.1754 - Val loss: 0.2228 - Training time: 88.83s
Epoch 1 - Train acc: 95.59 - Val acc: 92.85 - Train loss: 0.1365 - Val loss: 0.2067 - Training time: 88.46s
Epoch 2 - Train acc: 96.56 - Val acc: 92.75 - Train loss: 0.1088 - Val loss: 0.2064 - Training time: 88.74s
Test pruning iteration :1
	Score: 90.24
Epoch 0 - Train acc: 96.44 - Val acc: 95.02 - Train loss: 0.1095 - Val loss: 0.1423 - Training time: 88.52s
Epoch 1 - Train acc: 97.25 - Val acc: 95.28 - Train loss: 0.0868 - Val loss: 0.1362 - Training time: 88.43s
Epoch 2 - Train acc: 98.26 - Val acc: 95.49 - Train loss: 0.0595 - Val loss: 0.1306 - Training time: 88.77s
end number of flops: 699280000.0 	number of params: 57973740.0
Final Test:
	Score: 90.82000000000001
***  Alexnet 30%
number of flops: 823247104.0 	number of params: 61100840.0
Epoch 0 - Train acc: 82.87 - Val acc: 82.19 - Train loss: 0.5003 - Val loss: 0.5240 - Training time: 88.49s
Epoch 1 - Train acc: 88.09 - Val acc: 85.69 - Train loss: 0.3443 - Val loss: 0.4118 - Training time: 88.59s
Epoch 2 - Train acc: 91.36 - Val acc: 87.81 - Train loss: 0.2541 - Val loss: 0.3460 - Training time: 88.47s
Test:
	Score: 87.75
2 iterations to reduce 30.00% filters
Perform pruning iteration: 0
Layers that will be pruned {'features.6': 80, 'features.10': 29, 'features.0': 10, 'features.8': 30, 'features.3': 23}
convolution remaining after pruning {'features.6': 304, 'features.10': 227, 'features.0': 54, 'features.8': 226, 'features.3': 169}
Pruning filters.. 
Filters pruned 14.930555555555555%
Test:
	post prune Score: 11.24
Fine tuning to recover from prunning iteration.
Epoch 0 - Train acc: 90.09 - Val acc: 88.05 - Train loss: 0.2905 - Val loss: 0.3494 - Training time: 88.82s
Epoch 1 - Train acc: 92.58 - Val acc: 89.20 - Train loss: 0.2216 - Val loss: 0.3165 - Training time: 88.21s
Epoch 2 - Train acc: 93.58 - Val acc: 89.27 - Train loss: 0.1897 - Val loss: 0.3119 - Training time: 88.61s
Test pruning iteration :0
	Score: 88.01
Perform pruning iteration: 1
Layers that will be pruned {'features.8': 40, 'features.6': 69, 'features.3': 23, 'features.10': 38, 'features.0': 2}
convolution remaining after pruning {'features.8': 186, 'features.6': 235, 'features.3': 146, 'features.10': 189, 'features.0': 52}
Pruning filters.. 
Filters pruned 14.930555555555555%
Test:
	post prune Score: 12.740000000000002
Fine tuning to recover from prunning iteration.
Epoch 0 - Train acc: 91.71 - Val acc: 89.83 - Train loss: 0.2451 - Val loss: 0.2928 - Training time: 88.37s
Epoch 1 - Train acc: 92.55 - Val acc: 89.41 - Train loss: 0.2187 - Val loss: 0.2981 - Training time: 88.47s
Epoch 2 - Train acc: 94.94 - Val acc: 91.39 - Train loss: 0.1621 - Val loss: 0.2596 - Training time: 88.46s
Test pruning iteration :1
	Score: 88.62
end number of flops: 490793408.0 	number of params: 49979640.0
Final Test:
	Score: 88.62
***  Alexnet 50%
number of flops: 823247104.0 	number of params: 61100840.0
Epoch 0 - Train acc: 82.11 - Val acc: 80.86 - Train loss: 0.5207 - Val loss: 0.5503 - Training time: 88.77s
Epoch 1 - Train acc: 87.56 - Val acc: 85.86 - Train loss: 0.3589 - Val loss: 0.4184 - Training time: 88.38s
Epoch 2 - Train acc: 90.52 - Val acc: 87.24 - Train loss: 0.2790 - Val loss: 0.3677 - Training time: 87.16s
Test:
	Score: 86.53
2 iterations to reduce 50.00% filters
Perform pruning iteration: 0
Layers that will be pruned {'features.6': 128, 'features.8': 58, 'features.3': 37, 'features.10': 50, 'features.0': 15}
convolution remaining after pruning {'features.6': 256, 'features.8': 198, 'features.3': 155, 'features.10': 206, 'features.0': 49}
Pruning filters.. 
Filters pruned 25.0%
Test:
	post prune Score: 14.19
Fine tuning to recover from prunning iteration.
Epoch 0 - Train acc: 88.13 - Val acc: 86.85 - Train loss: 0.3474 - Val loss: 0.3844 - Training time: 88.44s
Epoch 1 - Train acc: 90.95 - Val acc: 88.23 - Train loss: 0.2629 - Val loss: 0.3344 - Training time: 88.28s
Epoch 2 - Train acc: 92.38 - Val acc: 88.91 - Train loss: 0.2296 - Val loss: 0.3173 - Training time: 88.35s
Test pruning iteration :0
	Score: 87.58
Perform pruning iteration: 1
Layers that will be pruned {'features.6': 99, 'features.3': 42, 'features.0': 16, 'features.8': 67, 'features.10': 64}
convolution remaining after pruning {'features.6': 157, 'features.3': 113, 'features.0': 33, 'features.8': 131, 'features.10': 142}
Pruning filters.. 
Filters pruned 25.0%
Test:
	post prune Score: 23.32
Fine tuning to recover from prunning iteration.
Epoch 0 - Train acc: 86.68 - Val acc: 85.25 - Train loss: 0.3919 - Val loss: 0.4311 - Training time: 88.38s
Epoch 1 - Train acc: 88.69 - Val acc: 86.24 - Train loss: 0.3354 - Val loss: 0.3989 - Training time: 88.34s
Epoch 2 - Train acc: 90.35 - Val acc: 86.81 - Train loss: 0.2853 - Val loss: 0.3793 - Training time: 88.24s
Test pruning iteration :1
	Score: 85.37
end number of flops: 287415904.0 	number of params: 42439128.0
Final Test:
	Score: 85.37
***  Alexnet 75%
number of flops: 823247104.0 	number of params: 61100840.0
Epoch 0 - Train acc: 81.14 - Val acc: 79.50 - Train loss: 0.5413 - Val loss: 0.5869 - Training time: 88.50s
Epoch 1 - Train acc: 87.52 - Val acc: 84.77 - Train loss: 0.3615 - Val loss: 0.4446 - Training time: 88.43s
Epoch 2 - Train acc: 90.72 - Val acc: 87.01 - Train loss: 0.2677 - Val loss: 0.3737 - Training time: 88.62s
Test:
	Score: 87.45
1 iterations to reduce 75.00% filters
Perform pruning iteration: 0
Layers that will be pruned {'features.6': 189, 'features.10': 90, 'features.3': 45, 'features.8': 94, 'features.0': 19}
convolution remaining after pruning {'features.6': 195, 'features.10': 166, 'features.3': 147, 'features.8': 162, 'features.0': 45}
Pruning filters.. 
Filters pruned 37.93402777777778%
Test:
	post prune Score: 14.26
Fine tuning to recover from prunning iteration.
Epoch 0 - Train acc: 85.25 - Val acc: 83.47 - Train loss: 0.4340 - Val loss: 0.4785 - Training time: 87.99s
Epoch 1 - Train acc: 87.08 - Val acc: 84.26 - Train loss: 0.3740 - Val loss: 0.4464 - Training time: 88.31s
Epoch 2 - Train acc: 87.21 - Val acc: 83.65 - Train loss: 0.3678 - Val loss: 0.4690 - Training time: 87.28s
Test pruning iteration :0
	Score: 83.19
end number of flops: 413704320.0 	number of params: 46326852.0
Final Test:
	Score: 83.19
***  Alexnet 0%
number of flops: 823247104.0 	number of params: 61100840.0
Epoch 0 - Train acc: 79.64 - Val acc: 77.88 - Train loss: 0.5814 - Val loss: 0.6231 - Training time: 88.75s
Epoch 1 - Train acc: 87.61 - Val acc: 84.63 - Train loss: 0.3668 - Val loss: 0.4316 - Training time: 88.03s
Epoch 2 - Train acc: 90.50 - Val acc: 87.25 - Train loss: 0.2744 - Val loss: 0.3656 - Training time: 88.51s
Test:
	Score: 87.19
Epoch 0 - Train acc: 89.75 - Val acc: 88.22 - Train loss: 0.2945 - Val loss: 0.3412 - Training time: 88.83s
Epoch 1 - Train acc: 93.50 - Val acc: 90.86 - Train loss: 0.1932 - Val loss: 0.2747 - Training time: 87.91s
Epoch 2 - Train acc: 94.81 - Val acc: 90.87 - Train loss: 0.1588 - Val loss: 0.2679 - Training time: 88.03s
Epoch 3 - Train acc: 96.00 - Val acc: 91.55 - Train loss: 0.1200 - Val loss: 0.2556 - Training time: 88.73s
Epoch 4 - Train acc: 96.32 - Val acc: 90.96 - Train loss: 0.1092 - Val loss: 0.2627 - Training time: 88.64s
Epoch 5 - Train acc: 97.84 - Val acc: 91.99 - Train loss: 0.0737 - Val loss: 0.2399 - Training time: 88.43s

Process finished with exit code -1
